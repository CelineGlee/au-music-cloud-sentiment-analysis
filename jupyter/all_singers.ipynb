{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430d6fbb",
   "metadata": {},
   "source": [
    "This code generates a new index called \"all-singers\" which contains all the posts that mention any of the singers within the scope of this research scenario, for accelerated aggregation and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "ES_URL = \"https://localhost:9200\"\n",
    "SRC_INDEX = \"mastodon-prod-v3\"\n",
    "DST_INDEX = \"all-singers\"\n",
    "AUTH = HTTPBasicAuth(\"elastic\", \"elastic\")\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "VERIFY_SSL = False\n",
    "\n",
    "with open(\"artists.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    artist_names = set(data[\"artists\"] + data[\"artists_au\"])\n",
    "    artist_terms = [name.lower() for name in artist_names]\n",
    "\n",
    "print(f\"Loaded {len(artist_terms)} unique artist names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195975dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_all_docs():\n",
    "    # Construct the initial search URL with scroll enabled (keeps the search context alive for 1 minute)\n",
    "    url = f\"{ES_URL}/{SRC_INDEX}/_search?scroll=1m\"\n",
    "    \n",
    "    # Define the search request body:\n",
    "    # - size: number of documents per batch\n",
    "    # - query: match all documents\n",
    "    # - Removed _source filter to fetch all fields\n",
    "    body = {\n",
    "        \"size\": 1000,\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    "\n",
    "    # Send the initial search request\n",
    "    resp = requests.post(url, auth=AUTH, headers=HEADERS, json=body, verify=VERIFY_SSL)\n",
    "    resp.raise_for_status()  # Raise an error if the request failed\n",
    "    result = resp.json()\n",
    "    \n",
    "    # Extract the scroll ID and the first batch of hits\n",
    "    scroll_id = result[\"_scroll_id\"]\n",
    "    hits = result[\"hits\"][\"hits\"]\n",
    "\n",
    "    # Continue fetching documents as long as there are hits\n",
    "    while hits:\n",
    "        # Yield each document in the current batch\n",
    "        yield from hits\n",
    "        \n",
    "        # Prepare the scroll request to get the next batch\n",
    "        scroll_url = f\"{ES_URL}/_search/scroll\"\n",
    "        scroll_body = {\n",
    "            \"scroll\": \"1m\",\n",
    "            \"scroll_id\": scroll_id\n",
    "        }\n",
    "        \n",
    "        # Send the scroll request\n",
    "        resp = requests.post(scroll_url, auth=AUTH, headers=HEADERS, json=scroll_body, verify=VERIFY_SSL)\n",
    "        resp.raise_for_status()\n",
    "        result = resp.json()\n",
    "        \n",
    "        # Extract the next batch of hits\n",
    "        hits = result[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_if_needed():\n",
    "    url = f\"{ES_URL}/{DST_INDEX}\"\n",
    "    resp = requests.head(url, auth=AUTH, verify=VERIFY_SSL)\n",
    "    if resp.status_code == 404:\n",
    "        resp = requests.put(url, auth=AUTH, verify=VERIFY_SSL)\n",
    "        resp.raise_for_status()\n",
    "        print(f\"Created index: {DST_INDEX}\")\n",
    "    else:\n",
    "        print(f\"Index already exists: {DST_INDEX}\")\n",
    "\n",
    "# Create target index (if not already created)\n",
    "create_index_if_needed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68573cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_artist(doc_source):\n",
    "    content = doc_source.get(\"content\", \"\")\n",
    "    content_lower = content.lower()\n",
    "    return any(artist in content_lower for artist in artist_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_insert(docs):\n",
    "    bulk_lines = \"\"\n",
    "    for doc in docs:\n",
    "        action = {\"index\": {\"_index\": DST_INDEX, \"_id\": doc[\"_id\"]}}\n",
    "        # Copy the entire document source\n",
    "        doc_source = doc[\"_source\"].copy()\n",
    "        # Ensure 'id' field matches '_id' if 'id' exists\n",
    "        if \"id\" in doc_source:\n",
    "            doc_source[\"id\"] = doc[\"_id\"]\n",
    "        bulk_lines += json.dumps(action) + \"\\n\"\n",
    "        bulk_lines += json.dumps(doc_source) + \"\\n\"\n",
    "    \n",
    "    bulk_url = f\"{ES_URL}/_bulk\"\n",
    "    resp = requests.post(bulk_url, auth=AUTH, headers=HEADERS, data=bulk_lines, verify=VERIFY_SSL)\n",
    "    resp.raise_for_status()\n",
    "    print(f\"Indexed {len(docs)} docs to '{DST_INDEX}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab954af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "count = 0\n",
    "\n",
    "for doc in scroll_all_docs():\n",
    "    if contains_artist(doc[\"_source\"]):\n",
    "        buffer.append(doc)\n",
    "\n",
    "    if len(buffer) >= 500:\n",
    "        bulk_insert(buffer)\n",
    "        count += len(buffer)\n",
    "        buffer = []\n",
    "\n",
    "if buffer:\n",
    "    bulk_insert(buffer)\n",
    "    count += len(buffer)\n",
    "\n",
    "print(f\"\\nâœ… Total indexed documents: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec556dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(ES_URL, auth=AUTH, verify=VERIFY_SSL)\n",
    "print(\"Connected to Elasticsearch\" if resp.status_code == 200 else \"Connection failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
